---
layout: default
---

<div class="row">
<p>
  Objects, and the interactions between them, are the foundations on which our understanding of the world is built [1].
  Similarly, abstractions centered around the perception and representation of objects play a key role in building
  human-like AI, supporting high-level cognitive abilities like causal reasoning, object-centric exploration,
  and problem solving [2,4,5,6]. Indeed, prior works have shown how relational reasoning and control problems can
  greatly benefit from having object descriptions [2,7]. Yet, many of the current methods in machine learning focus on
  a less structured approach in which objects are only implicitly represented [3], posing a challenge for
  interpretability and the reuse of knowledge across tasks. Motivated by the above observations, there has been a
  recent effort to reinterpret various learning problems from the perspective of object-oriented representations
  [2,4,5,6].
</p>
<p>
  In this workshop, we will showcase a variety of approaches in object-oriented learning, with three particular
  emphases. Our first interest is in learning object representations in an unsupervised manner. Although computer vision
  has made an enormous amount of progress in learning about objects via supervised methods, we believe that learning
  about objects with little to no supervision is preferable: it minimizes labeling costs, and also supports adaptive
  representations that can be changed depending on the particular situation and goal. The second primary interest of
  this workshop is to explore how object-oriented representations can be leveraged for downstream tasks such as
  reinforcement learning and causal reasoning. Lastly, given the central importance of objects in human cognition, we
  will highlight interdisciplinary perspectives from cognitive science and neuroscience on how people perceive and
  understand objects.
</p>
</div>

<div id="sponsors" class="row">
<h2>Sponsors</h2>
<div class="break"></div>
<div>
<p>
  <a href="http://deepmind.com"><img src="images/deepmind.png" height="80px"/></a>
  <a href="https://www.kakaobrain.com"><img src="images/kakaobrain.svg" height="40px"/></a>
</p>
</div>
</div>

<div id="organizers" class="row">
<h2>Organizers</h2>
<div class="break"></div>
<ul>
  <li><b><a href="http://www.sungjinahn.com">Sungjin Ahn</a></b> (Rutgers University)</li>
  <li><b><a href="http://akosiorek.github.io/about/">Adam R. Kosiorek</a></b> (DeepMind / Oxford)</li>
  <li><b><a href="http://www.jesshamrick.com">Jessica B. Hamrick</a></b> (DeepMind)</li>
  <li><b><a href="http://www.sjoerdvansteenkiste.com">Sjoerd van Steenkiste</a></b> (IDSIA)</li>
  <li><b><a href="https://yoshuabengio.org/">Yoshua Bengio</a></b> (MILA, Université de Montréal)</li>
</ul>
</div>

<!--<div id="pc" class="row">-->
<!--<h2>Program Committee</h2>-->
<!--<table>-->
<!--  <tr>-->
<!--  <td>Adam Marblestone</td>-->
<!--  <td>Aishwarya Agrawal</td>-->
<!--  <td>Andrea Banino</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Andrew Jaegle</td>-->
<!--  <td><a href="http://anselmrothe.github.io">Anselm Rothe</a></td>-->
<!--  <td>Ari Holtzman</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Bas van Opheusden</td>-->
<!--  <td>Ben Peloquin</td>-->
<!--  <td>Bill Thompson</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Charlie Nash</td>-->
<!--  <td>Danfei Xu</td>-->
<!--  <td>Emin Orhan</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td><a href="http://stanford.edu/~ebiyik">Erdem Biyik</a></td>-->
<!--  <td>Erin Grant</td>-->
<!--  <td>Jon Gauthier</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Josh Merel</td>-->
<!--  <td><a href="https://twitter.com/joshuacpeterson">Joshua Peterson</a></td>-->
<!--  <td>Kelsey Allen</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Kevin Ellis</td>-->
<!--  <td>Kevin McKee</td>-->
<!--  <td>Kevin Smith</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Leila Wehbe</td>-->
<!--  <td><a href="https://people.eecs.berkeley.edu/~lisa_anne/-->
<!--">Lisa Anne Hendricks</a></td>-->
<!--  <td>Luis Piloto</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Mark Ho</td>-->
<!--  <td><a href="https://www.people.hps.cam.ac.uk/index/teaching-officers/halina">Marta Halina</a></td>-->
<!--  <td>Marta Kryven</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Matthew Overlan</td>-->
<!--  <td>Max Kleiman-Weiner</td>-->
<!--  <td><a href="http://maxwellforbes.com">Maxwell Forbes</a></td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Maxwell Nye</td>-->
<!--  <td><a href="http://mbchang.github.io/">Michael Chang</a></td>-->
<!--  <td>Minae Kwon</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Pedro Tsividis</td>-->
<!--  <td>Peter Battaglia</td>-->
<!--  <td><a href="https://qiongzhang.github.io">Qiong Zhang</a></td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Raphael Koster</td>-->
<!--  <td>Richard Futrell</td>-->
<!--  <td><a href="https://rxdhawkins.com">Robert Hawkins</a></td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Sandy Huang</td>-->
<!--  <td>Stephan Meylan</td>-->
<!--  <td>Suraj Nair</td>-->
<!--  </tr>-->
<!--  <tr>-->
<!--  <td>Tal Linzen</td>-->
<!--  <td>Tina Zhu</td>-->
<!--  <td><a href="https://www.waikeenvong.com/">Wai Keen Vong</a></td>-->
<!--  </tr>-->
<!--</table>-->
<!--</div>-->

<div id="references" class="row">
<h2>References</h2>
<ol>
  <li>Spelke, E. S., & Kinzler, K. D. (2007). Core knowledge. Developmental science, 10(1), 89-96.</li>
  <li>Bapst, V., Sanchez-Gonzalez, A., Doersch, C., Stachenfeld, K. L., Kohli, P., Battaglia, P. W., & Hamrick, J. B. (2019). Structured agents for physical construction. ICML 2019.</li>
  <li>Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). Human-level control through deep reinforcement learning. Nature, 518(7540), 529-533.</li>
  <li>Kosiorek, A., Kim, H., Teh, Y.W. and Posner, I., (2018). Sequential attend, infer, repeat: Generative modelling of moving objects. In Advances in Neural Information Processing Systems 2018.</li>
  <li>Lin, Z., Wu, Y.F., Peri, S.V., Sun, W., Singh, G., Deng, F., Jiang, J. and Ahn, S., (2020). SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition. ICLR 2020.</li>
  <li>van Steenkiste, S., Chang, M., Greff, K., & Schmidhuber, J. (2018). Relational neural expectation maximization: Unsupervised discovery of objects and their interactions. ICLR 2018.</li>
  <li>Diuk, C., Cohen, A., & Littman, M. L. (2008, July). An object-oriented representation for efficient reinforcement learning. ICML 2008.</li>
</ol>
</div>